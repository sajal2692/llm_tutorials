{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agentic Design Patterns: Query Routing\n",
        "\n",
        "Deciding how to handle a user query based on different parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install langgraph langchain langchain_openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UwN1No7mFied"
      },
      "outputs": [],
      "source": [
        "\n",
        "# imports\n",
        "import os\n",
        "\n",
        "from langchain_community.retrievers import WikipediaRetriever\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6Fp6rP5cqcqZ"
      },
      "outputs": [],
      "source": [
        "# set environment variables\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"REMOVED_SECRET\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGEuMyMsAtip"
      },
      "source": [
        "Retrieve the data from Wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "np3IRXO6Fig1"
      },
      "outputs": [],
      "source": [
        "# setup the retriever\n",
        "retriever = WikipediaRetriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "docs = retriever.invoke(\"Manchester United\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'title': 'Manchester United F.C.',\n",
              " 'summary': \"Manchester United Football Club, commonly referred to as Man United (often stylised as Man Utd), or simply United, is a professional football club based in Old Trafford, Greater Manchester, England. The club competes in the Premier League, the top tier of English football. Nicknamed the Red Devils, they were founded as Newton Heath LYR Football Club in 1878, but changed their name to Manchester United in 1902. After a spell playing in Clayton, Manchester, the club moved to their current stadium, Old Trafford, in 1910.\\nDomestically, Manchester United have won a record 20 top-flight league titles, 13 FA Cups, 6 League Cups and a record 21 FA Community Shields. Additionally, in international football, they have won the European Cup/UEFA Champions League three times, and the UEFA Europa League, the UEFA Cup Winners' Cup, the UEFA Super Cup, the Intercontinental Cup and the FIFA Club World Cup once each. In 1968, under the management of Matt Busby, 10 years after eight of the club's players were killed in the Munich air disaster, they became the first English club to win the European Cup. Sir Alex Ferguson is the club's longest-serving and most successful manager, winning 38 trophies, including 13 league titles, five FA Cups, and two Champions League titles between 1986 and 2013. In the 1998–99 season, under Ferguson, the club became the first in the history of English football to achieve the continental treble of the Premier League, FA Cup and UEFA Champions League. In winning the UEFA Europa League under José Mourinho in 2016–17, they became one of five clubs to have won the original three main UEFA club competitions (the Champions League, Europa League and Cup Winners' Cup).  They have won the Premier League three years in a row twice; for the first 21 years of the Premier League they came 1st (13), 2nd (5) or 3rd (3).\\nManchester United is one of the most widely supported football clubs in the world and has rivalries with Liverpool, Manchester City, Arsenal and Leeds United. Manchester United was the highest-earning football club in the world for 2016–17, with an annual revenue of €676.3 million, and the world's third-most-valuable football club in 2019, valued at £3.15 billion ($3.81 billion). After being floated on the London Stock Exchange in 1991, the club was taken private in 2005 after a purchase by American businessman Malcolm Glazer valued at almost £800 million, of which over £500 million of borrowed money became the club's debt. From 2012, some shares of the club were listed on the New York Stock Exchange, although the Glazer family retains overall ownership and control of the club.\",\n",
              " 'source': 'https://en.wikipedia.org/wiki/Manchester_United_F.C.'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0].metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Manchester United Football Club, commonly referred to as Man United (often stylised as Man Utd), or simply United, is a professional football club based in Old Trafford, Greater Manchester, England. T\n"
          ]
        }
      ],
      "source": [
        "print(docs[0].page_content[:200])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a QA chain with the data retrieved from Wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lyh5FH7dr6fk"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o\")\n",
        "qa = ConversationalRetrievalChain.from_llm(model, retriever=retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_wikipedia(question):\n",
        "    \"\"\"Query the Wikipedia retriever with a question.\"\"\"\n",
        "    chat_history = [] # no chat history for this tutorial\n",
        "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
        "    return result[\"answer\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Manchester United Football Club, commonly referred to as Man United or simply United, is a professional football club based in Old Trafford, Greater Manchester, England. The club competes in the Premier League, which is the top tier of English football. Nicknamed the Red Devils, they were originally founded as Newton Heath LYR Football Club in 1878 and changed their name to Manchester United in 1902. They moved to their current stadium, Old Trafford, in 1910.\\n\\nManchester United is one of the most successful and widely supported football clubs in the world. Domestically, they have won a record 20 top-flight league titles, 13 FA Cups, 6 League Cups, and a record 21 FA Community Shields. Internationally, they have won the European Cup/UEFA Champions League three times and have secured the UEFA Europa League, the UEFA Cup Winners' Cup, the UEFA Super Cup, the Intercontinental Cup, and the FIFA Club World Cup once each. \\n\\nThe club has a storied history, including being the first English club to win the European Cup in 1968 under the management of Matt Busby. Sir Alex Ferguson is their longest-serving and most successful manager, having won 38 trophies, including 13 league titles and two Champions League titles, between 1986 and 2013. The club achieved a historic treble in the 1998-99 season by winning the Premier League, FA Cup, and UEFA Champions League.\\n\\nManchester United has fierce rivalries with clubs such as Liverpool, Manchester City, Arsenal, and Leeds United. The club has been under the ownership of the Glazer family since 2005.\""
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ask_wikipedia(\"What is Manchester United?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's try asking the wikipedia retriever a question based on recent news about Manchester United, such as transfer news."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"I don't have specific information on current transfer rumors. For the latest updates on Manchester United's potential signings, I recommend checking reliable sports news sources or the club's official announcements.\""
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ask_wikipedia(\"Who is rumored to be the next player that Manchester United buys?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-Yojp-QBRYy"
      },
      "source": [
        "Create a web search chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValidationError",
          "evalue": "1 validation error for TavilySearchAPIWrapper\n__root__\n  Did not find tavily_api_key, please add an environment variable `TAVILY_API_KEY` which contains it, or pass `tavily_api_key` as a named parameter. (type=value_error)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtavily_search\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TavilySearchResults\n\u001b[0;32m----> 3\u001b[0m web_search_tool \u001b[38;5;241m=\u001b[39m \u001b[43mTavilySearchResults\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/projects/github/sajal2692/llm_tutorials/blog_posts/adaptive_rag_with_langgraph/.venv/lib/python3.11/site-packages/pydantic/v1/main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
            "File \u001b[0;32m~/projects/github/sajal2692/llm_tutorials/blog_posts/adaptive_rag_with_langgraph/.venv/lib/python3.11/site-packages/pydantic/v1/main.py:1064\u001b[0m, in \u001b[0;36mvalidate_model\u001b[0;34m(model, input_data, cls)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(ErrorWrapper(MissingError(), loc\u001b[38;5;241m=\u001b[39mfield\u001b[38;5;241m.\u001b[39malias))\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 1064\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mfield\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mvalidate_all \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field\u001b[38;5;241m.\u001b[39mvalidate_always:\n\u001b[1;32m   1067\u001b[0m     values[name] \u001b[38;5;241m=\u001b[39m value\n",
            "File \u001b[0;32m~/projects/github/sajal2692/llm_tutorials/blog_posts/adaptive_rag_with_langgraph/.venv/lib/python3.11/site-packages/pydantic/v1/fields.py:437\u001b[0m, in \u001b[0;36mModelField.get_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_default\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m smart_deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/projects/github/sajal2692/llm_tutorials/blog_posts/adaptive_rag_with_langgraph/.venv/lib/python3.11/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for TavilySearchAPIWrapper\n__root__\n  Did not find tavily_api_key, please add an environment variable `TAVILY_API_KEY` which contains it, or pass `tavily_api_key` as a named parameter. (type=value_error)"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search = DuckDuckGoSearchResults()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvYG2kyUFijH"
      },
      "outputs": [],
      "source": [
        "rag_prompt = \"\"\"You are an AI  assistant. Your main task is to answer questions people may have about Sajal.\n",
        "Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
        "Question: {question}\n",
        "Context: {context}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt_template = ChatPromptTemplate.from_template(rag_prompt)\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | rag_prompt_template\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs3aD9q6BUTw"
      },
      "source": [
        "Examples of good results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ssSjxzizFilN",
        "outputId": "3d468071-9df6-47ca-ef2c-224f9705c1d5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sajal graduated from the University of Melbourne with a Master of Information Technology, majoring in Computing, in August 2016.'"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke(\"When did Sajal graduate from University of Melbourne?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "8Ptt39MyFinj",
        "outputId": "2b9eae14-3d71-460e-dfef-efac5d5570b6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'At Unscrambl, Sajal was a key member of the NLP Engineering team, where he helped enhance the natural language understanding of their business analytics platform, focusing on advancing Named Entity Recognition (NER), intent recognition, and ANNOY model functionalities. He developed the Natural Language to SQL system data preparation pipeline using NLTK and spaCy, significantly reducing manual effort and boosting system efficiency. Additionally, Sajal collaborated in designing and developing NLP-driven chatbot products and led the deployment of these solutions for clients across Asia, impacting over 100,000 monthly users.'"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag_chain.invoke(\"What did Sajal do at Unscrambl?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biAbW43zBW30"
      },
      "source": [
        "Examples of subpar results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "pUu1VudfFip6",
        "outputId": "ecf28cb6-4dcd-4959-cb70-ee8dc8e0c01f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"The provided documents do not specify the exact number of countries Sajal has worked in. However, his education and mentoring activities suggest he has connections to Australia and India, and possibly interacts with international students globally through his role as a mentor at Udacity. Without more specific information on his professional work locations, it's not possible to give a precise count of countries he has worked in.\""
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# incorrect result\n",
        "rag_chain.invoke(\"How many countries has sajal worked in?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib21OztLy8iv",
        "outputId": "fa4ae7a8-7c61-4124-ae5d-97de253a85af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='# Sajal Sharma  \\n## Contact Info  \\n+65 9077-9093 | contact@sajalsharma.com | [LinkedIn](linkedin.com/in/sajals) | [GitHub](github.com/sajal2692)', metadata={'Header 1': 'Sajal Sharma', 'Header 2': 'Contact Info'}),\n",
              " Document(page_content='## Languages  \\n- Hindi (Native or Bilingual)\\n- English (Native or Bilingual)\\n- German (Elementary)', metadata={'Header 1': 'Sajal Sharma', 'Header 2': 'Languages'}),\n",
              " Document(page_content='## Activities  \\n- Mentor & Project Reviewer, Udacity: Coached 100+ international students enrolled in Data Science courses. Recognised as an elite mentor in 2021 with A+ mentor performance grade based on student feedback scores.\\n- Mentor, STEM Industry Mentoring Programme, The University of Melbourne: Jul 2020 - Present\\n- Creator, Data Science Portfolio: Github repo with 900+ stars showcasing various classical Data Science projects.', metadata={'Header 1': 'Sajal Sharma', 'Header 2': 'Activities'}),\n",
              " Document(page_content='## Education  \\n**The University of Melbourne**\\nMaster of Information Technology, Major in Computing\\nMelbourne, Australia\\nAug 2014 – Aug 2016  \\n**Bharatiya Vidyapeeth University**\\nBachelor of Computer Applications\\nNew Delhi, India\\nJul 2010 – Jul 2013', metadata={'Header 1': 'Sajal Sharma', 'Header 2': 'Education'})]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check what documents were retrieved from the vector db\n",
        "retriever.get_relevant_documents(\"How many countries has sajal worked in?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohXWZID9BiHE"
      },
      "source": [
        "Since there are no chunks that can directly answer the given question, the similarity search struggles to find relevant information.\n",
        "\n",
        "Another example of a similar case:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "YO4yTlYixtYj",
        "outputId": "5ab48db3-a234-4e7c-e525-90fa54219541"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Throughout his career, Sajal has held the following positions:\\n1. Mentor & Project Reviewer at Udacity\\n2. Mentor at the STEM Industry Mentoring Programme, The University of Melbourne\\n3. Creator of a Data Science Portfolio on GitHub\\n4. Senior AI Engineer at Splore, a Temasek-backed AI startup (contracted via Unscrambl), Singapore'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# incorrect / incomplete result\n",
        "rag_chain.invoke(\"list all the positions that sajal has held throughout his career\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6FrLnvYyPx4"
      },
      "source": [
        "Building a Corrective RAG workflow using LangGraph\n",
        "\n",
        "1. Grade retrieved documents based on the question\n",
        "2. If no relevant documents found, then pass in the whole source document as the context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COSLhZ-CyXch"
      },
      "outputs": [],
      "source": [
        "# Defining the state class which holds data related to the current state\n",
        "from typing import Dict, TypedDict\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        keys: A dictionary where each key is a string.\n",
        "    \"\"\"\n",
        "    keys: Dict[str, any]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sppn3fce6yXw"
      },
      "source": [
        "Defining the nodes of the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8danfQWH5H00"
      },
      "outputs": [],
      "source": [
        "def retrieve_documents(state):\n",
        "  \"\"\"Node to retrieve documents, by using the query from the state\"\"\"\n",
        "  print(\"---RETRIEVE DOCUMENTS---\") # print statements to track flow\n",
        "  state_dict = state[\"keys\"]\n",
        "  question = state_dict[\"question\"]\n",
        "  documents = retriever.get_relevant_documents(question)\n",
        "  return {\"keys\": {\"question\": question, \"documents\": documents}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qUGr-yNEKil"
      },
      "outputs": [],
      "source": [
        "generation_answer_chain = rag_prompt_template | llm | StrOutputParser()\n",
        "def generate_with_retrieved_documents(state):\n",
        "  \"\"\"Node to generate answer using retrieved documents\"\"\"\n",
        "  print(\"---GENERATE USING RETRIEVED DOCUMENTS---\")\n",
        "  state_dict = state[\"keys\"]\n",
        "  question = state_dict[\"question\"]\n",
        "  documents = state_dict[\"documents\"]\n",
        "  answer = generation_answer_chain.invoke({\"question\": question, \"context\": documents})\n",
        "  return {\"keys\": {\"question\": question, \"response\": answer}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRCk5YuH6u4c"
      },
      "outputs": [],
      "source": [
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
        "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
        "\n",
        "grader_prompt = \"\"\"\n",
        "You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
        "Retrieved document: \\n\\n {context} \\n\\n\n",
        "User Question: {question} \\n\n",
        "When assessing the relevance of a retrieved document to a user question, consider whether the document can provide a complete answer to the question posed. A document is considered relevant only if it contains all the necessary information to fully answer the user's inquiry without requiring additional context or assumptions.\n",
        "Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
        "Do not return anything other than a 'yes' or 'no'.\n",
        "\"\"\"\n",
        "\n",
        "grader_prompt_template = PromptTemplate(template=grader_prompt, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "# pydantic class for grade, to be used with openai function calling\n",
        "class grade(BaseModel):\n",
        "    \"\"\"Binary score for relevance check.\"\"\"\n",
        "    binary_score: str = Field(description=\"Relevance score 'yes' or 'no'\")\n",
        "\n",
        "grade_tool_openai = convert_to_openai_tool(grade)\n",
        "\n",
        "llm_with_grader_tool = llm.bind(\n",
        "    tools=[grade_tool_openai],\n",
        "    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"grade\"}}\n",
        ")\n",
        "\n",
        "tool_parser = PydanticToolsParser(tools=[grade])\n",
        "\n",
        "grader_chain = grader_prompt_template | llm_with_grader_tool | tool_parser\n",
        "\n",
        "def grade_documents(state):\n",
        "  \"\"\"Node to grade documents, filter out irrelevant documents and assess whether need to run generation on whole document\"\"\"\n",
        "  print(\"---GRADE DOCUMENTS---\")\n",
        "  state_dict = state[\"keys\"]\n",
        "  question = state_dict[\"question\"]\n",
        "  documents = state_dict[\"documents\"]\n",
        "\n",
        "  filtered_documents = []\n",
        "  run_with_all_data = False\n",
        "  for doc in documents:\n",
        "    score = grader_chain.invoke({\"context\": documents, \"question\": question})\n",
        "    grade = score[0].binary_score\n",
        "    if grade == \"yes\":\n",
        "      print(\"---GRADE: FOUND RELEVANT DOCUMENT---\")\n",
        "      filtered_documents.append(doc)\n",
        "  if not filtered_documents:\n",
        "    print(\"---GRADE: DID NOT FIND ANY RELEVANT DOCUMENTS\")\n",
        "    run_with_all_data = True\n",
        "\n",
        "  return {\n",
        "      \"keys\": {\n",
        "          \"documents\": filtered_documents,\n",
        "          \"question\": question,\n",
        "          \"run_with_all_data\": run_with_all_data\n",
        "          }\n",
        "      }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JqhROje5cD4"
      },
      "outputs": [],
      "source": [
        "def generate_answer_using_all_data(state):\n",
        "  \"\"\"Node to generate the answer using the complete document\"\"\"\n",
        "  print(\"---GENERATING ANSWER USING ALL DATA\")\n",
        "  state_dict = state[\"keys\"]\n",
        "  question = state_dict[\"question\"]\n",
        "  answer = generation_answer_chain.invoke({\"question\": question, \"context\": full_markdown_document})\n",
        "  return {\"keys\": {\"question\": question, \"response\": answer}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWPLoAMwHYnV"
      },
      "source": [
        "Define the conditional edge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mwt2RC6FiuW"
      },
      "outputs": [],
      "source": [
        "def decide_to_use_all_data(state):\n",
        "  \"\"\"Conditional edge that decides the next node to run\"\"\"\n",
        "  state_dict = state[\"keys\"]\n",
        "  run_with_all_data = state_dict[\"run_with_all_data\"]\n",
        "\n",
        "  if run_with_all_data:\n",
        "      return \"generate_answer_using_all_data\"\n",
        "  else:\n",
        "      return \"rag\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M95D_qfoB5y9"
      },
      "source": [
        "Defining the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69_1m-wiHjmO"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import END, StateGraph\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        keys: A dictionary where each key is a string.\n",
        "    \"\"\"\n",
        "    keys: Dict[str, any]\n",
        "\n",
        "\n",
        "def compile_graph():\n",
        "  workflow = StateGraph(GraphState)\n",
        "  ### define the nodes\n",
        "  workflow.add_node(\"retrieve\", retrieve_documents)\n",
        "  workflow.add_node(\"grade_documents\", grade_documents)\n",
        "  workflow.add_node(\"generate_answer_with_retrieved_documents\", generate_with_retrieved_documents)\n",
        "  workflow.add_node(\"generate_answer_using_all_data\", generate_answer_using_all_data)\n",
        "  ### build the graph\n",
        "  workflow.set_entry_point(\"retrieve\")\n",
        "  workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
        "  workflow.add_conditional_edges(\n",
        "      \"grade_documents\",\n",
        "      decide_to_use_all_data,\n",
        "      {\n",
        "          \"rag\": \"generate_answer_with_retrieved_documents\",\n",
        "          \"generate_answer_using_all_data\": \"generate_answer_using_all_data\",\n",
        "      }\n",
        "  )\n",
        "  workflow.add_edge(\"generate_answer_with_retrieved_documents\", END)\n",
        "  workflow.add_edge(\"generate_answer_using_all_data\", END)\n",
        "  ### compile the graph\n",
        "  app = workflow.compile()\n",
        "  return app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfVoPoi1B8_y"
      },
      "source": [
        "Compiling the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1eLbw4MIiBt"
      },
      "outputs": [],
      "source": [
        "app = compile_graph()\n",
        "def response_from_graph(question):\n",
        "  \"\"\"Returns the response from the graph\"\"\"\n",
        "  return app.invoke({\"keys\": {\"question\": question}})[\"keys\"][\"response\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SjZr2vgCArd"
      },
      "source": [
        "Trying on the same example as previously"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhLKqhzDINZZ",
        "outputId": "ad78af7b-5260-45c6-882d-3c9d6ffeacc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---RETRIEVE DOCUMENTS---\n",
            "---GRADE DOCUMENTS---\n",
            "---GRADE: DID NOT FIND ANY RELEVANT DOCUMENTS\n",
            "---GENERATING ANSWER USING ALL DATA\n",
            "Sajal has worked in at least three countries: Singapore, the Philippines, and India. His work in Singapore is mentioned with OneByZero and Splore, a Temasek-backed AI startup. Additionally, he developed a proof of concept for a major bank in the Philippines and was a key member of Unscrambl's NLP Engineering team in India.\n"
          ]
        }
      ],
      "source": [
        "# testing out the flow with crag\n",
        "print(response_from_graph(\"How many countries has sajal worked in?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTGyZFlXIgrZ",
        "outputId": "7ab20cdc-eadb-48e2-9ff0-ad362a907935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---RETRIEVE DOCUMENTS---\n",
            "---GRADE DOCUMENTS---\n",
            "---GRADE: DID NOT FIND ANY RELEVANT DOCUMENTS\n",
            "---GENERATING ANSWER USING ALL DATA\n",
            "Throughout his career, Sajal has held the following positions:\n",
            "1. Lead AI Engineer at OneByZero (contracted via Unscrambl), Singapore.\n",
            "2. Senior AI Engineer at Splore, a Temasek-backed AI startup (contracted via Unscrambl), Singapore.\n",
            "3. Senior Machine Learning Engineer at Unscrambl, India.\n",
            "4. Machine Learning Engineer at Unscrambl, India.\n"
          ]
        }
      ],
      "source": [
        "print(response_from_graph(\"list all the positions that sajal has held throughout his career\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePiE1m9hCHI-"
      },
      "source": [
        "The graph is able to handle cases where the retrieved chunks can be used to answer the question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pu-dyXrJ6LQ",
        "outputId": "d38ead0f-cbdf-49f7-fae1-f9ad1172d69d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---RETRIEVE DOCUMENTS---\n",
            "---GRADE DOCUMENTS---\n",
            "---GRADE: FOUND RELEVANT DOCUMENT---\n",
            "---GRADE: FOUND RELEVANT DOCUMENT---\n",
            "---GRADE: FOUND RELEVANT DOCUMENT---\n",
            "---GRADE: FOUND RELEVANT DOCUMENT---\n",
            "---GENERATE USING RETRIEVED DOCUMENTS---\n",
            "Yes, Sajal has created a popular GitHub repository. His Data Science Portfolio on GitHub has garnered over 900 stars, showcasing various classical Data Science projects. This indicates a significant level of recognition and appreciation from the GitHub community.\n"
          ]
        }
      ],
      "source": [
        "print(response_from_graph(\"Has sajal created any popular github repositories?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNmCyviwKPTW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
