{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Agentic RAG Workflow\n",
    "\n",
    "Building a complete agentic RAG system that combines query routing, document grading, and query rewriting using LangGraph.\n",
    "\n",
    "This notebook implements:\n",
    "- Query Routing\n",
    "- Document Relevance Grading\n",
    "- Self Correction through Query Rewriting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Literal, Annotated, Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_chroma.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import BaseMessage, AIMessage\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API keys\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading blog posts from sajalsharma.com...\n",
      "✓ Loaded: https://sajalsharma.com/posts/introduction-to-agentic-rag/\n",
      "✓ Loaded: https://sajalsharma.com/posts/agentic-rag-query-router-langgraph/\n",
      "✓ Loaded: https://sajalsharma.com/posts/corrective-rag-langgraph/\n"
     ]
    }
   ],
   "source": [
    "# Load articles from sajalsharma.com\n",
    "urls = [\n",
    "    \"https://sajalsharma.com/posts/introduction-to-agentic-rag/\",\n",
    "    \"https://sajalsharma.com/posts/agentic-rag-query-router-langgraph/\",\n",
    "    \"https://sajalsharma.com/posts/corrective-rag-langgraph/\",\n",
    "]\n",
    "\n",
    "# Load documents\n",
    "print(\"Loading blog posts from sajalsharma.com...\")\n",
    "docs = []\n",
    "for url in urls:\n",
    "    try:\n",
    "        loader = WebBaseLoader(url)\n",
    "        docs.extend(loader.load())\n",
    "        print(f\"✓ Loaded: {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to load {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 177 document chunks\n"
     ]
    }
   ],
   "source": [
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, \n",
    "    chunk_overlap=100\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs)\n",
    "print(f\"\\nCreated {len(doc_splits)} document chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    collection_name=\"blog-posts\",\n",
    "    persist_directory=\"chroma\"\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our comprehensive agentic RAG graph.\n",
    "    \n",
    "    Attributes:\n",
    "        messages: Conversation history\n",
    "        query: Original user query\n",
    "        chosen_datasource: Selected retrieval source\n",
    "        retrieved_docs: Documents retrieved from any source\n",
    "        relevance_check: Whether documents are relevant\n",
    "        query_rewrite_count: Number of query rewrites attempted\n",
    "        final_answer: Generated response\n",
    "    \"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    query: str\n",
    "    chosen_datasource: str\n",
    "    retrieved_docs: List[Document]\n",
    "    relevance_check: str\n",
    "    query_rewrite_count: int\n",
    "    final_answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Router Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "\n",
    "# Define routing schema\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route query to appropriate datasource.\"\"\"\n",
    "    datasource: Literal[\"vectorstore\", \"web_search\", \"direct_response\"] = Field(\n",
    "        description=\"Choose between vectorstore for Sajal's blog content about RAG and agents, web_search for current events, or direct_response for general knowledge\"\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        description=\"Brief explanation for the routing decision\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Router prompt\n",
    "router_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert at routing user queries to the appropriate data source.\n",
    "    \n",
    "    Based on the query, choose where to route it:\n",
    "    - vectorstore: For questions about Sajal's blog posts on agentic RAG, corrective RAG, query routing, or related RAG patterns\n",
    "    - web_search: For current events, recent developments, or information requiring real-time data\n",
    "    - direct_response: For general knowledge, definitions, or questions that don't require external data\n",
    "    \n",
    "    Analyze the query carefully and make the best routing decision.\"\"\"),\n",
    "    (\"human\", \"{query}\")\n",
    "])\n",
    "\n",
    "# Create router chain\n",
    "router_chain = router_prompt | llm.with_structured_output(RouteQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_query(state: GraphState) -> GraphState:\n",
    "    \"\"\"Route query to the appropriate datasource.\"\"\"\n",
    "    print(\"*** ROUTING QUERY ***\")\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    router_result = router_chain.invoke({\"query\": query})\n",
    "    \n",
    "    print(f\"Routing to: {router_result.datasource}\")\n",
    "    print(f\"Reasoning: {router_result.reasoning}\")\n",
    "    \n",
    "    return {\n",
    "        \"chosen_datasource\": router_result.datasource,\n",
    "        \"messages\": [AIMessage(content=f\"Routing to {router_result.datasource}: {router_result.reasoning}\")]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Retrieval Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector store retrieval\n",
    "def retrieve_from_vectorstore(state: GraphState) -> GraphState:\n",
    "    \"\"\"Retrieve documents from vector store.\"\"\"\n",
    "    print(\"*** RETRIEVING FROM VECTOR STORE ***\")\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    documents = retriever.invoke(query)\n",
    "    return {\n",
    "        \"retrieved_docs\": documents,\n",
    "        \"messages\": [AIMessage(content=f\"Retrieved {len(documents)} documents from vector store\")]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web search retrieval\n",
    "web_search_retriever = TavilySearchAPIRetriever(k=3)\n",
    "\n",
    "def retrieve_from_web(state: GraphState) -> GraphState:\n",
    "    \"\"\"Retrieve documents from web search.\"\"\"\n",
    "    print(\"*** RETRIEVING FROM WEB SEARCH ***\")\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    documents = web_search_retriever.invoke(query)\n",
    "    return {\n",
    "        \"retrieved_docs\": documents,\n",
    "        \"messages\": [AIMessage(content=f\"Retrieved {len(documents)} documents from web search\")]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: prepare_direct_response node removed as it was redundant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Grading with Self-Reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document grading schema\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary score for document relevance.\"\"\"\n",
    "    binary_score: Literal[\"yes\", \"no\"] = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "# Grading prompt\n",
    "grade_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a grader assessing relevance of retrieved documents to a user question.\n",
    "    \n",
    "    Retrieved document:\n",
    "    {document}\n",
    "    \n",
    "    User question: {question}\n",
    "    \n",
    "    If the document is relevant to the user's original question, grade it as relevant.\n",
    "    Give a binary score 'yes' or 'no' to indicate relevance.\"\"\"),\n",
    "    (\"human\", \"Grade the document.\")\n",
    "])\n",
    "\n",
    "grade_chain = grade_prompt | llm.with_structured_output(GradeDocuments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state: GraphState) -> GraphState:\n",
    "    \"\"\"Grade the relevance of retrieved documents.\"\"\"\n",
    "    print(\"*** GRADING DOCUMENTS ***\")\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    documents = state[\"retrieved_docs\"]\n",
    "    \n",
    "    if not documents:\n",
    "        return {\"relevance_check\": \"no_documents\"}\n",
    "    \n",
    "    # Grade each document\n",
    "    relevant_docs = []\n",
    "    for i, doc in enumerate(documents):\n",
    "        # Get a snippet of the document content for display\n",
    "        snippet = doc.page_content[:50].replace('\\n', ' ').strip()\n",
    "        if len(doc.page_content) > 50:\n",
    "            snippet += \"...\"\n",
    "        \n",
    "        grade = grade_chain.invoke({\n",
    "            \"document\": doc.page_content,\n",
    "            \"question\": query\n",
    "        })\n",
    "        \n",
    "        if grade.binary_score == \"yes\":\n",
    "            print(f\"✓ Document {i+1} graded as RELEVANT\")\n",
    "            print(f\"  Snippet: {doc.page_content}\")\n",
    "            relevant_docs.append(doc)\n",
    "        else:\n",
    "            print(f\"✗ Document {i+1} graded as NOT RELEVANT\")\n",
    "            print(f\"  Snippet: {doc.page_content}\")\n",
    "    \n",
    "    # Update state based on grading results\n",
    "    if relevant_docs:\n",
    "        return {\n",
    "            \"retrieved_docs\": relevant_docs,\n",
    "            \"relevance_check\": \"relevant\",\n",
    "            \"messages\": [AIMessage(content=f\"Found {len(relevant_docs)} relevant documents\")]\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"relevance_check\": \"not_relevant\",\n",
    "            \"messages\": [AIMessage(content=\"No relevant documents found\")]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Rewriting for Better Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query rewriting prompt\n",
    "rewrite_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are a query rewriting expert. The user's original query didn't retrieve relevant documents.\n",
    "    \n",
    "    Analyze the query and rewrite it to improve retrieval chances:\n",
    "    - Make it more specific or more general as appropriate\n",
    "    - Add synonyms or related terms\n",
    "    - Rephrase to target likely document content\n",
    "    - Consider the retrieval failure and adjust accordingly\n",
    "    \n",
    "    Original query: {query}\n",
    "    Previous datasource: {datasource}\"\"\"),\n",
    "    (\"human\", \"Provide a rewritten query that will retrieve better results.\")\n",
    "])\n",
    "\n",
    "rewrite_chain = rewrite_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_query(state: GraphState) -> GraphState:\n",
    "    \"\"\"Rewrite the query for better retrieval.\"\"\"\n",
    "    print(\"*** REWRITING QUERY ***\")\n",
    "    \n",
    "    original_query = state[\"query\"]\n",
    "    datasource = state.get(\"chosen_datasource\", \"unknown\")\n",
    "    count = state.get(\"query_rewrite_count\", 0)\n",
    "    \n",
    "    # Rewrite the query\n",
    "    rewritten_query = rewrite_chain.invoke({\n",
    "        \"query\": original_query,\n",
    "        \"datasource\": datasource\n",
    "    })\n",
    "    \n",
    "    print(f\"Original: {original_query}\")\n",
    "    print(f\"Rewritten: {rewritten_query}\")\n",
    "    \n",
    "    return {\n",
    "        \"query\": rewritten_query,\n",
    "        \"query_rewrite_count\": count + 1,\n",
    "        \"messages\": [AIMessage(content=f\"Query rewritten: {rewritten_query}\")]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG generation prompt\n",
    "rag_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an AI assistant. Answer the question based on the retrieved context.\n",
    "    \n",
    "    Use the following pieces of retrieved context to answer the question. \n",
    "    If you don't know the answer, say that you don't know.\n",
    "    Keep the answer concise but comprehensive.\n",
    "    \n",
    "    Context:\n",
    "    {context}\"\"\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "rag_chain = rag_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_context(state: GraphState) -> GraphState:\n",
    "    \"\"\"Generate answer using retrieved documents.\"\"\"\n",
    "    print(\"*** GENERATING WITH CONTEXT ***\")\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    documents = state[\"retrieved_docs\"]\n",
    "    \n",
    "    # Format documents for context\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "    \n",
    "    # Generate response\n",
    "    answer = rag_chain.invoke({\n",
    "        \"context\": context,\n",
    "        \"question\": query\n",
    "    })\n",
    "    \n",
    "    return {\n",
    "        \"final_answer\": answer,\n",
    "        \"messages\": [AIMessage(content=\"Generated response with context\")]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_direct_response(state: GraphState) -> GraphState:\n",
    "    \"\"\"Generate response without retrieval context.\"\"\"\n",
    "    print(\"*** GENERATING DIRECT RESPONSE ***\")\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    direct_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful AI assistant. Answer the question based on your knowledge.\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "    \n",
    "    direct_chain = direct_prompt | llm | StrOutputParser()\n",
    "    answer = direct_chain.invoke({\"question\": query})\n",
    "    \n",
    "    return {\n",
    "        \"final_answer\": answer,\n",
    "        \"messages\": [AIMessage(content=\"Generated direct response\")]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_no_info_response(state: GraphState) -> GraphState:\n",
    "    \"\"\"Generate response when no relevant information is found.\"\"\"\n",
    "    print(\"*** GENERATING NO INFO RESPONSE ***\")\n",
    "    \n",
    "    query = state[\"query\"]\n",
    "    attempts = state.get(\"query_rewrite_count\", 0)\n",
    "    \n",
    "    answer = f\"\"\"I couldn't find relevant information to answer your question: \"{query}\"\n",
    "    \n",
    "I attempted to search {attempts + 1} time(s) across different sources and reformulated the query, \n",
    "but no relevant documents were found. This might be because:\n",
    "- The information isn't available in my current knowledge sources\n",
    "- The topic is too specific or recent\n",
    "- The query needs to be approached differently\n",
    "\n",
    "Please try rephrasing your question or providing more context.\"\"\"\n",
    "    \n",
    "    return {\n",
    "        \"final_answer\": answer,\n",
    "        \"messages\": [AIMessage(content=\"No relevant information found\")]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Edge Decision Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_retry(state: GraphState) -> Literal[\"rewrite_query\", \"no_info\"]:\n",
    "    \"\"\"Determine if we should retry with rewritten query.\"\"\"\n",
    "    rewrite_count = state.get(\"query_rewrite_count\", 0)\n",
    "    max_retries = 2\n",
    "    \n",
    "    if rewrite_count < max_retries:\n",
    "        return \"rewrite_query\"\n",
    "    else:\n",
    "        return \"no_info\"\n",
    "\n",
    "def route_after_grading(state: GraphState) -> Literal[\"generate\", \"retry_decision\"]:\n",
    "    \"\"\"Route based on document grading results.\"\"\"\n",
    "    relevance = state.get(\"relevance_check\", \"\")\n",
    "    \n",
    "    if relevance == \"relevant\":\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        return \"retry_decision\"\n",
    "\n",
    "def route_to_retrieval(state: GraphState) -> Literal[\"vectorstore\", \"web_search\", \"direct_response\"]:\n",
    "    \"\"\"Route to appropriate retrieval method.\"\"\"\n",
    "    return state[\"chosen_datasource\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the Complete Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Comprehensive agentic RAG workflow compiled successfully\n"
     ]
    }
   ],
   "source": [
    "def compile_workflow():\n",
    "    \"\"\"Compile the complete agentic RAG workflow.\"\"\"\n",
    "    workflow = StateGraph(GraphState)\n",
    "    \n",
    "    # Add all nodes\n",
    "    workflow.add_node(\"route_query\", route_query)\n",
    "    workflow.add_node(\"retrieve_vectorstore\", retrieve_from_vectorstore)\n",
    "    workflow.add_node(\"retrieve_web\", retrieve_from_web)\n",
    "    workflow.add_node(\"grade_documents\", grade_documents)\n",
    "    workflow.add_node(\"rewrite_query\", rewrite_query)\n",
    "    workflow.add_node(\"generate_with_context\", generate_with_context)\n",
    "    workflow.add_node(\"generate_direct\", generate_direct_response)\n",
    "    workflow.add_node(\"generate_no_info\", generate_no_info_response)\n",
    "    \n",
    "    # Build the graph flow\n",
    "    workflow.set_entry_point(\"route_query\")\n",
    "    \n",
    "    # Routing from query router - direct_response goes straight to generate_direct\n",
    "    workflow.add_conditional_edges(\n",
    "        \"route_query\",\n",
    "        route_to_retrieval,\n",
    "        {\n",
    "            \"vectorstore\": \"retrieve_vectorstore\",\n",
    "            \"web_search\": \"retrieve_web\",\n",
    "            \"direct_response\": \"generate_direct\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # After retrieval, grade documents\n",
    "    workflow.add_edge(\"retrieve_vectorstore\", \"grade_documents\")\n",
    "    workflow.add_edge(\"retrieve_web\", \"grade_documents\")\n",
    "    \n",
    "    # After grading, decide next step\n",
    "    workflow.add_conditional_edges(\n",
    "        \"grade_documents\",\n",
    "        route_after_grading,\n",
    "        {\n",
    "            \"generate\": \"generate_with_context\",\n",
    "            \"retry_decision\": \"rewrite_query\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # After rewriting, check retry limit\n",
    "    workflow.add_conditional_edges(\n",
    "        \"rewrite_query\",\n",
    "        should_retry,\n",
    "        {\n",
    "            \"rewrite_query\": \"route_query\",\n",
    "            \"no_info\": \"generate_no_info\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # All generation nodes lead to END\n",
    "    workflow.add_edge(\"generate_with_context\", END)\n",
    "    workflow.add_edge(\"generate_direct\", END)\n",
    "    workflow.add_edge(\"generate_no_info\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Compile the workflow\n",
    "app = compile_workflow()\n",
    "print(\"✓ Comprehensive agentic RAG workflow compiled successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_workflow(query: str):\n",
    "    \"\"\"Run the agentic RAG workflow and return the response.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    initial_state = {\n",
    "        \"messages\": [],\n",
    "        \"query\": query,\n",
    "        \"query_rewrite_count\": 0\n",
    "    }\n",
    "    \n",
    "    result = app.invoke(initial_state)\n",
    "    return result[\"final_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUERY: How does corrective RAG handle irrelevant documents?\n",
      "============================================================\n",
      "\n",
      "*** ROUTING QUERY ***\n",
      "Routing to: vectorstore\n",
      "Reasoning: The query specifically asks about 'corrective RAG,' which is a topic covered in Sajal's blog posts. The user is seeking an explanation related to a RAG pattern, making the vectorstore (containing Sajal's blog content) the most appropriate data source.\n",
      "*** RETRIEVING FROM VECTOR STORE ***\n",
      "*** GRADING DOCUMENTS ***\n",
      "✓ Document 1 graded as RELEVANT\n",
      "  Snippet: This is where Corrective RAG (CRAG) comes into play. It enhances the traditional RAG framework by introducing a lightweight retrieval evaluator that assesses the quality of retrieved documents and assigns a confidence score. This score then informs whether to proceed with the generated answer or seek further information, potentially through approaches such as web-search, or in the case of this document, passing in more context to the LLM.\n",
      "✓ Document 2 graded as RELEVANT\n",
      "  Snippet: The initial retrieval process is performed as in standard RAG.\n",
      "The agent assesses retrieved documents—checking for relevance, completeness, and contradictions.\n",
      "If needed, the agent triggers corrective actions, such as:\n",
      "\n",
      "Rewriting the query and performing another retrieval attempt.\n",
      "Fetching additional information from alternative sources.\n",
      "Discarding irrelevant or low-confidence documents, to reduce noise in the generation step.\n",
      "✓ Document 3 graded as RELEVANT\n",
      "  Snippet: Corrective RAG\n",
      "Corrective RAG introduces reflection mechanisms, allowing the system to refine its retrieval and response generation by reflecting the quality of the retrieval or generation steps. For example, instead of accepting retrieved documents as they were returned from the knowledge souce, the agent validates their quality, and can course correct before proceeding.\n",
      "An Example Workflow\n",
      "✗ Document 4 graded as NOT RELEVANT\n",
      "  Snippet: Introduction\n",
      "\n",
      "What if chunks from a relevant document are not relevant enough for an LLM to answer a question in your RAG system?\n",
      "*** GENERATING WITH CONTEXT ***\n",
      "\n",
      "RESPONSE:\n",
      "Corrective RAG handles irrelevant documents by evaluating the quality of the retrieved documents using a retrieval evaluator that assigns a confidence score. If documents are found to be irrelevant or low-confidence, the system can discard them to reduce noise in the generation step. Additionally, the agent may take corrective actions such as rewriting the query, performing another retrieval attempt, or fetching information from alternative sources to ensure more relevant and accurate context is provided to the language model.\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Query about corrective RAG from Sajal's blog (should route to vectorstore)\n",
    "response1 = run_workflow(\"How does corrective RAG handle irrelevant documents?\")\n",
    "print(f\"\\nRESPONSE:\\n{response1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUERY: What are the main agentic patterns for RAG according to Sajal?\n",
      "============================================================\n",
      "\n",
      "*** ROUTING QUERY ***\n",
      "Routing to: vectorstore\n",
      "Reasoning: The query specifically asks about Sajal's perspective on agentic patterns for RAG, which would be covered in Sajal's blog posts. Therefore, the vectorstore containing Sajal's blog content is the appropriate data source.\n",
      "*** RETRIEVING FROM VECTOR STORE ***\n",
      "*** GRADING DOCUMENTS ***\n",
      "✗ Document 1 graded as NOT RELEVANT\n",
      "  Snippet: These behaviors align with the agentic patterns discussed earlier, transforming RAG into a more intelligent and self-correcting process. Agentic RAG actively guides its own retrieval strategy, ensuring higher-quality and more contextually relevant answers.\n",
      "Agentic Patterns for RAG\n",
      "✓ Document 2 graded as RELEVANT\n",
      "  Snippet: An Introduction to Agentic RAG\n",
      "\n",
      "\n",
      "    Skip to content    Sajal Sharma              \n",
      "Posts\n",
      "   \n",
      "Tags\n",
      "   \n",
      "About Me\n",
      "      Search                        Go back    An Introduction to Agentic RAG Published:Mar 4, 2025  Table of contents\n",
      "Open Table of contents\n",
      "\n",
      "Introduction\n",
      "\n",
      "A Refresher on RAG\n",
      "What are Agentic Systems?\n",
      "What makes RAG Agentic?\n",
      "\n",
      "\n",
      "Agentic Patterns for RAG\n",
      "\n",
      "Query Analysis\n",
      "Query Rewriting\n",
      "Planning & Multi-Step Retrieval\n",
      "Self Evaluation through Reflection\n",
      "Bringing It All Together\n",
      "✓ Document 3 graded as RELEVANT\n",
      "  Snippet: Introduction\n",
      "Welcome to the second post in my Agentic RAG series! In my previous post on “An Introduction to Agentic RAG”, I explored various Agentic RAG patterns and workflows including Query Analysis, Query Rewriting, Multi-Step Retrieval, and Self-Evaluation through Reflection. I also demonstrated how these patterns come together to create sophisticated architectures like Single Agent Router, Corrective RAG, and Adaptive RAG.\n",
      "✗ Document 4 graded as NOT RELEVANT\n",
      "  Snippet: Let’s explore some of the design patterns for Agentic RAG in more detail. Each of the below patterns represents a mechanisms that allows the RAG system to make intelligent decisions at different stages of the retrieval and response generation pipeline. Throughout the diagrams, I refrain from calling the agentic nodes as actual AI Agents, given the vagueness of the definition. Nevertheless, any node where an LLM call or chain is used for a purpose other than generation, could be deemed “agentic”\n",
      "*** GENERATING WITH CONTEXT ***\n",
      "\n",
      "RESPONSE:\n",
      "According to Sajal, the main agentic patterns for RAG are:\n",
      "\n",
      "1. Query Analysis\n",
      "2. Query Rewriting\n",
      "3. Planning & Multi-Step Retrieval\n",
      "4. Self Evaluation through Reflection\n",
      "\n",
      "These patterns are used to create more sophisticated and adaptive RAG (Retrieval-Augmented Generation) systems.\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Query about agentic patterns from Sajal's blog\n",
    "response2 = run_workflow(\"What are the main agentic patterns for RAG according to Sajal?\")\n",
    "print(f\"\\nRESPONSE:\\n{response2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUERY: What are the latest LangGraph features released in 2024?\n",
      "============================================================\n",
      "\n",
      "*** ROUTING QUERY ***\n",
      "Routing to: web_search\n",
      "Reasoning: The query asks for the latest features of LangGraph released in 2024, which requires up-to-date information about recent developments. This information is best obtained through a web search.\n",
      "*** RETRIEVING FROM WEB SEARCH ***\n",
      "*** GRADING DOCUMENTS ***\n",
      "✗ Document 1 graded as NOT RELEVANT\n",
      "  Snippet: Zach Anderson Jul 13, 2024 16:26 LangChain, a leading platform in the AI development space, has released its latest updates, showcasing new use cases and enhancements across its ecosystem. According to the LangChain Blog , the updates cover advancements in LangGraph Cloud, LangSmith's self-improving evaluators, and revamped documentation for\n",
      "✓ Document 2 graded as RELEVANT\n",
      "  Snippet: We also have a new stable release of LangGraph. By LangChain 6 min read Jun 27, 2024 (Oct '24) Edit: Since the launch of LangGraph Cloud, we now have multiple deployment options alongside LangGraph Studio - which now fall under LangGraph Platform.\n",
      "✓ Document 3 graded as RELEVANT\n",
      "  Snippet: langgraph: release 0.4.4 ; update for consistency; lint again; use list; lint + update; update; update; update; langgraph: fix drawing graph with root channel; langgraph: fix graph drawing for self-loops; Merge branch 'main' into clean [Proposal] add gitmcp badge for simple LLM-accessible documentation ; Change LG Cloud > Platform\n",
      "*** GENERATING WITH CONTEXT ***\n",
      "\n",
      "RESPONSE:\n",
      "The latest LangGraph features released in 2024 include:\n",
      "\n",
      "- Multiple deployment options with the introduction of LangGraph Cloud, alongside LangGraph Studio, now collectively referred to as the LangGraph Platform.\n",
      "- Improvements in graph drawing, including fixes for drawing graphs with root channels and handling self-loops.\n",
      "- Updates for consistency, code linting, and documentation enhancements.\n",
      "- Addition of a gitmcp badge for simple LLM-accessible documentation.\n",
      "\n",
      "These updates are part of the stable release 0.4.4 and subsequent improvements.\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Current events query (should route to web search)\n",
    "response3 = run_workflow(\"What are the latest LangGraph features released in 2024?\")\n",
    "print(f\"\\nRESPONSE:\\n{response3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUERY: What is the difference between a list and a tuple in Python?\n",
      "============================================================\n",
      "\n",
      "*** ROUTING QUERY ***\n",
      "Routing to: direct_response\n",
      "Reasoning: This is a general programming knowledge question about Python data structures and does not require external data or specific blog content.\n",
      "*** GENERATING DIRECT RESPONSE ***\n",
      "\n",
      "RESPONSE:\n",
      "In Python, **lists** and **tuples** are both used to store collections of items, but they have some important differences:\n",
      "\n",
      "### 1. Mutability\n",
      "- **List:** Mutable (can be changed after creation; you can add, remove, or modify elements).\n",
      "- **Tuple:** Immutable (cannot be changed after creation; elements cannot be added, removed, or modified).\n",
      "\n",
      "### 2. Syntax\n",
      "- **List:** Defined using square brackets `[ ]`\n",
      "  ```python\n",
      "  my_list = [1, 2, 3]\n",
      "  ```\n",
      "- **Tuple:** Defined using parentheses `( )`\n",
      "  ```python\n",
      "  my_tuple = (1, 2, 3)\n",
      "  ```\n",
      "\n",
      "### 3. Methods\n",
      "- **List:** Has many built-in methods (like `append()`, `remove()`, `pop()`, etc.).\n",
      "- **Tuple:** Has very few built-in methods (mainly `count()` and `index()`).\n",
      "\n",
      "### 4. Use Cases\n",
      "- **List:** Used when you need a collection of items that may change during the program.\n",
      "- **Tuple:** Used when you want to ensure the data cannot be changed (for example, as keys in dictionaries or for fixed data).\n",
      "\n",
      "### 5. Performance\n",
      "- **Tuple:** Slightly faster than lists for iteration and access, due to their immutability.\n",
      "\n",
      "### Example\n",
      "\n",
      "```python\n",
      "# List example\n",
      "my_list = [1, 2, 3]\n",
      "my_list[0] = 10  # Allowed\n",
      "\n",
      "# Tuple example\n",
      "my_tuple = (1, 2, 3)\n",
      "# my_tuple[0] = 10  # Not allowed, will raise TypeError\n",
      "```\n",
      "\n",
      "**Summary Table:**\n",
      "\n",
      "| Feature      | List         | Tuple        |\n",
      "|--------------|--------------|--------------|\n",
      "| Mutable      | Yes          | No           |\n",
      "| Syntax       | [1, 2, 3]    | (1, 2, 3)    |\n",
      "| Methods      | Many         | Few          |\n",
      "| Use as dict key | No        | Yes          |\n",
      "| Performance  | Slower       | Faster       |\n",
      "\n",
      "**In short:**  \n",
      "Use a **list** when you need a mutable sequence, and a **tuple** when you need an immutable sequence.\n"
     ]
    }
   ],
   "source": [
    "# Test 4: General knowledge query (should route to direct response)\n",
    "response4 = run_workflow(\"What is the difference between a list and a tuple in Python?\")\n",
    "print(f\"\\nRESPONSE:\\n{response4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUERY: is agentic rag bad?\n",
      "============================================================\n",
      "\n",
      "*** ROUTING QUERY ***\n",
      "Routing to: vectorstore\n",
      "Reasoning: The query is specifically about 'agentic RAG,' which is a topic covered in Sajal's blog posts. The user is likely seeking an informed perspective or analysis from those blog posts, making the vectorstore the appropriate data source.\n",
      "*** RETRIEVING FROM VECTOR STORE ***\n",
      "*** GRADING DOCUMENTS ***\n",
      "✗ Document 1 graded as NOT RELEVANT\n",
      "  Snippet: What makes RAG Agentic?\n",
      "Agentic RAG introduces autonomy and adaptability into the standard RAG pipeline by allowing the system to actively control the retrieval process rather than relying on a fixed retrieval-then-generate flow.\n",
      "This means that instead of a linear pipeline, where retrieval is a single-step precursor to generation, an Agentic RAG system introduces decision points throughout the process. The system might:\n",
      "✗ Document 2 graded as NOT RELEVANT\n",
      "  Snippet: Agentic RAG represents a significant evolution in retrieval-augmented generation, introducing autonomy, reasoning, and adaptability to improve how AI retrieves and generates information. By moving beyond a fixed retrieve-then-generate pipeline, Agentic RAG enables dynamic decision-making—choosing the best data source, refining queries, iterating on retrieval, and self-evaluating responses before finalizing an answer. This adaptability allows it to handle complex queries, ensure information\n",
      "✗ Document 3 graded as NOT RELEVANT\n",
      "  Snippet: An Introduction to Agentic RAG\n",
      "\n",
      "\n",
      "    Skip to content    Sajal Sharma              \n",
      "Posts\n",
      "   \n",
      "Tags\n",
      "   \n",
      "About Me\n",
      "      Search                        Go back    An Introduction to Agentic RAG Published:Mar 4, 2025  Table of contents\n",
      "Open Table of contents\n",
      "\n",
      "Introduction\n",
      "\n",
      "A Refresher on RAG\n",
      "What are Agentic Systems?\n",
      "What makes RAG Agentic?\n",
      "\n",
      "\n",
      "Agentic Patterns for RAG\n",
      "\n",
      "Query Analysis\n",
      "Query Rewriting\n",
      "Planning & Multi-Step Retrieval\n",
      "Self Evaluation through Reflection\n",
      "Bringing It All Together\n",
      "✗ Document 4 graded as NOT RELEVANT\n",
      "  Snippet: This modular, adaptable approach makes Agentic RAG vastly more powerful than traditional RAG, as it can tailor retrieval strategies in real time based on the nature of the query.\n",
      "In the next section, we will explore practical examples of how these patterns come together in real-world Agentic RAG pipelines.\n",
      "Examples of Agentic RAG Pipelines\n",
      "We will focus on three possible approaches that demonstrate how the above patterns can be applied in practice.\n",
      "Single Agent Router\n",
      "*** REWRITING QUERY ***\n",
      "Original: is agentic rag bad?\n",
      "Rewritten: Is having an agentic retrieval-augmented generation (RAG) system considered harmful or problematic?  \n",
      "What are the potential risks or downsides of using agentic RAG models?  \n",
      "Are there any criticisms or concerns about agentic RAG approaches in AI?\n",
      "*** ROUTING QUERY ***\n",
      "Routing to: vectorstore\n",
      "Reasoning: The query specifically asks about agentic retrieval-augmented generation (RAG) systems, their risks, downsides, and criticisms. These topics are directly related to Sajal's blog posts and writings on agentic RAG and related patterns, making the vectorstore the most appropriate data source.\n",
      "*** RETRIEVING FROM VECTOR STORE ***\n",
      "*** GRADING DOCUMENTS ***\n",
      "✗ Document 1 graded as NOT RELEVANT\n",
      "  Snippet: Agentic RAG represents a significant evolution in retrieval-augmented generation, introducing autonomy, reasoning, and adaptability to improve how AI retrieves and generates information. By moving beyond a fixed retrieve-then-generate pipeline, Agentic RAG enables dynamic decision-making—choosing the best data source, refining queries, iterating on retrieval, and self-evaluating responses before finalizing an answer. This adaptability allows it to handle complex queries, ensure information\n",
      "✓ Document 2 graded as RELEVANT\n",
      "  Snippet: However, introducing agentic behavior comes with trade-offs. Additional decision points increase latency and computational costs, and maintaining prompts, retrieval strategies, and evaluation pipelines requires ongoing refinement. Despite this complexity, for applications where accuracy, reliability, and adaptability are critical, the benefits outweigh the challenges. By shifting from a passive retriever to an active reasoning system, Agentic RAG makes AI-powered retrieval more robust,\n",
      "✗ Document 3 graded as NOT RELEVANT\n",
      "  Snippet: retriever to an active reasoning system, Agentic RAG makes AI-powered retrieval more robust, context-aware, and verifiable, paving the way for more advanced, real-world-ready knowledge systems.\n",
      "✗ Document 4 graded as NOT RELEVANT\n",
      "  Snippet: Retrieval-Augmented Generation (RAG) is a technique addresses the above issue by giving an LLM access to external knowledge. Instead of relying solely on their pre-trained data, RAG systems retrieve relevant documents from databases, vector stores, or APIs and feed them as additional context to the LLM before generating a response. This makes the model’s responses more accurate, up-to-date, and grounded in relevant contextual information.\n",
      "*** GENERATING WITH CONTEXT ***\n",
      "\n",
      "RESPONSE:\n",
      "Having an agentic retrieval-augmented generation (RAG) system is not inherently harmful or problematic, but there are important trade-offs and potential risks to consider:\n",
      "\n",
      "**Potential Risks and Downsides:**\n",
      "- **Increased Complexity:** Agentic RAG systems introduce more decision points, which increases system complexity. This can make them harder to maintain, debug, and audit.\n",
      "- **Higher Latency and Computational Costs:** The additional reasoning and decision-making steps can slow down response times and require more computational resources.\n",
      "- **Maintenance Overhead:** Ongoing refinement is needed for prompts, retrieval strategies, and evaluation pipelines, which can be resource-intensive.\n",
      "- **Unintended Behaviors:** More autonomy in the system can lead to unexpected or undesired actions if not carefully controlled and monitored.\n",
      "- **Reliability Concerns:** If not properly designed, agentic systems may make poor decisions about what information to retrieve or how to use it, potentially reducing accuracy.\n",
      "\n",
      "**Criticisms and Concerns:**\n",
      "- **Transparency and Interpretability:** As agentic RAG systems become more complex, it can be harder to understand and explain their behavior, raising concerns about transparency.\n",
      "- **Control and Safety:** Giving more autonomy to AI systems can introduce risks if the agentic behavior is not well-aligned with user goals or safety requirements.\n",
      "- **Resource Usage:** The increased computational demands may not be justified for all applications, especially where simpler retrieval methods suffice.\n",
      "\n",
      "**Summary:**  \n",
      "Agentic RAG systems offer benefits in accuracy, reliability, and adaptability, especially for complex tasks. However, they come with increased complexity, higher costs, and potential risks related to control, transparency, and maintenance. These trade-offs should be carefully considered when deciding whether to use agentic RAG approaches.\n"
     ]
    }
   ],
   "source": [
    "# Test 5: Vague query that might require rewriting\n",
    "response5 = run_workflow(\"is agentic rag bad?\")\n",
    "print(f\"\\nRESPONSE:\\n{response5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUERY: What is Sajal's favorite food?\n",
      "============================================================\n",
      "\n",
      "*** ROUTING QUERY ***\n",
      "Routing to: direct_response\n",
      "Reasoning: The query is asking for a personal preference (Sajal's favorite food), which is general knowledge unless specifically mentioned in Sajal's blog posts. Since there is no indication that this is covered in the blog content, and it is not a current event, direct_response is the best choice.\n",
      "*** GENERATING DIRECT RESPONSE ***\n",
      "\n",
      "RESPONSE:\n",
      "I don't have enough information to determine who Sajal is or what their favorite food might be. If you provide more context about Sajal, I may be able to help!\n"
     ]
    }
   ],
   "source": [
    "# Test 6: Query with no relevant information in Sajal's blog (should trigger no_info response)\n",
    "response6 = run_workflow(\"What is Sajal's favorite food?\")\n",
    "print(f\"\\nRESPONSE:\\n{response6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This comprehensive agentic RAG workflow demonstrates:\n",
    "\n",
    "1. **Intelligent Query Routing**: Automatically selects the most appropriate data source\n",
    "2. **Document Quality Control**: Validates retrieved documents before generation\n",
    "3. **Self-Correction**: Rewrites queries when initial retrieval fails\n",
    "4. **Graceful Failure Handling**: Provides meaningful responses when no relevant information exists\n",
    "\n",
    "The modular design allows for easy extension and customization based on specific requirements.\n",
    "\n",
    "### Key Benefits:\n",
    "\n",
    "- **Adaptive Behavior**: System adjusts strategy based on query type and retrieval results\n",
    "- **Quality Assurance**: Document grading ensures only relevant information is used\n",
    "- **Robustness**: Multiple fallback mechanisms prevent system failures\n",
    "- **Transparency**: Clear workflow execution makes the system interpretable\n",
    "\n",
    "### Potential Extensions:\n",
    "\n",
    "- Multi-source parallel retrieval\n",
    "- Confidence scoring for responses\n",
    "- Citation management\n",
    "- Query decomposition for complex questions\n",
    "- Hybrid search strategies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
